{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##I am scraping data on NHL games between October 2017 and January 2020 using BeautifulSoup:\n",
    "import requests\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       http://www.nhl.com/scores/htmlreports/20172018...\n",
       "1       http://www.nhl.com/scores/htmlreports/20172018...\n",
       "2       http://www.nhl.com/scores/htmlreports/20172018...\n",
       "3       http://www.nhl.com/scores/htmlreports/20172018...\n",
       "4       http://www.nhl.com/scores/htmlreports/20172018...\n",
       "                              ...                        \n",
       "1266    http://www.nhl.com/scores/htmlreports/20172018...\n",
       "1267    http://www.nhl.com/scores/htmlreports/20172018...\n",
       "1268    http://www.nhl.com/scores/htmlreports/20172018...\n",
       "1269    http://www.nhl.com/scores/htmlreports/20172018...\n",
       "1270    http://www.nhl.com/scores/htmlreports/20172018...\n",
       "Name: 0, Length: 1271, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##The url for the official boxscore of a NHL game in the 2017-2018 season is as follows:\n",
    "\n",
    "##http://www.nhl.com/scores/htmlreports/20172018/GS020001.HTM\n",
    "\n",
    "##The last four digits of the 5- digit GSO number define the specific game in a season (up to 1,271), ordered by game start time and date. \n",
    "##For example, the first game of the 2019-2020 season, which was played on October 2nd, 2019, has the url\n",
    "\n",
    "##http://www.nhl.com/scores/htmlreports/20192020/GS020001.HTM\n",
    "\n",
    "##Because the 2019-2020 season is still in progress, the last box score I'm scraping is the 688th game in the 2019-2020 season:\n",
    "\n",
    "##http://www.nhl.com/scores/htmlreports/20192020/GS020630.HTM\n",
    "\n",
    "\n",
    "\n",
    "##Now I write a function to return a list of urls for each season by treating the url as three strings:\n",
    "##urla, the beginning of the url that I hold constant in each season, including everything up to the game indexing number,\n",
    "##urlb, the 5-digit number that defines the game,\n",
    "##urlc, which is constant for all games\n",
    "##And I'll splice the lists of three strings into a list of full urls, which are strings\n",
    "\n",
    "def url2017_18(x):\n",
    "    urlb_num=20000+x\n",
    "    urlb=str(urlb_num)\n",
    "    urla=\"http://www.nhl.com/scores/htmlreports/20172018/GS0\"\n",
    "    urlc=\".HTM\"\n",
    "    url=urla+urlb+urlc\n",
    "\n",
    "    \n",
    "    return(url)\n",
    "\n",
    "##Now I'll create a list of positive integers up to 1271, the the list of urls for the 2017-2018 season\n",
    "\n",
    "def createList(p1, p2):\n",
    "    return list(range(p1, p2+1))\n",
    "\n",
    "p1, p2 = 1, 1271\n",
    "\n",
    "\n",
    "##And use the DataFrame function from Pandas to convert my integer list into a single-columned Dataframe:\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "##And now I'll apply the url2017_18 function to my integer column to create a column of with the url address of the boxscore\n",
    "##of each game:\n",
    "df_p = pd.DataFrame(createList(p1, p2))\n",
    "url_p=df_p[0].apply(url2017_18)\n",
    "\n",
    "url_p\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##I'll do the same thing for the next season (and a half):\n",
    "\n",
    "##2018-2019:\n",
    "\n",
    "def url2018_19(x):\n",
    "    urlb_num=20000+x\n",
    "    urlb=str(urlb_num)\n",
    "    urla=\"http://www.nhl.com/scores/htmlreports/20182019/GS0\"\n",
    "    urlc=\".HTM\"\n",
    "    url=urla+urlb+urlc\n",
    "\n",
    "    \n",
    "    return(url)\n",
    "\n",
    "def createList(q1, q2):\n",
    "    return list(range(q1, q2+1))\n",
    "\n",
    "q1, q2 = 1, 1271\n",
    "\n",
    "df_q = pd.DataFrame(createList(q1, q2))\n",
    "url_q=df_q[0].apply(url2018_19)\n",
    "\n",
    "##2019-2020:\n",
    "\n",
    "def url_201920(x):\n",
    "    urlb_num=20000+x\n",
    "    urlb=str(urlb_num)\n",
    "    urla=\"http://www.nhl.com/scores/htmlreports/20192020/GS0\"\n",
    "    urlc=\".HTM\"\n",
    "    url=urla+urlb+urlc\n",
    "\n",
    "    \n",
    "    return(url)\n",
    "\n",
    "\n",
    "def createList(r1, r2):\n",
    "    return list(range(r1, r2+1))\n",
    "r1, r2 = 1, 688\n",
    "\n",
    "df_r = pd.DataFrame(createList(r1, r2))\n",
    "url_r=df_r[0].apply(url_201920)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       http://www.nhl.com/scores/htmlreports/20172018...\n",
       "1       http://www.nhl.com/scores/htmlreports/20172018...\n",
       "2       http://www.nhl.com/scores/htmlreports/20172018...\n",
       "3       http://www.nhl.com/scores/htmlreports/20172018...\n",
       "4       http://www.nhl.com/scores/htmlreports/20172018...\n",
       "                              ...                        \n",
       "3225    http://www.nhl.com/scores/htmlreports/20192020...\n",
       "3226    http://www.nhl.com/scores/htmlreports/20192020...\n",
       "3227    http://www.nhl.com/scores/htmlreports/20192020...\n",
       "3228    http://www.nhl.com/scores/htmlreports/20192020...\n",
       "3229    http://www.nhl.com/scores/htmlreports/20192020...\n",
       "Name: 0, Length: 3230, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Now I'll combine the three columns of urls into one:\n",
    "\n",
    "url_pq=url_p.append(pd.DataFrame(data = url_q), ignore_index=True)\n",
    "url_c=url_pq.append(pd.DataFrame(data = url_r), ignore_index=True)\n",
    "url_c=url_c.iloc[:,0]\n",
    "\n",
    "##And I now have a column including the offical url address of every NHL game between 10/04/2017 and 1/9/2020:\n",
    "\n",
    "url_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now I'll export the urls to a csv file:\n",
    "\n",
    "export_csv = url_c.to_csv(r'C:/Users/maya rowen/Downloads/url.csv', index = None, header=True)\n",
    "\n",
    "##Next up: I'll use BeautifulSoup to scrape the html associated with each url..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
